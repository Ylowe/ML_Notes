{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### IMPORTING LIBRARIES #####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', style='whitegrid', font_scale=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Cheat Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because ___FUCK___ math notation and the horse it rode in on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting - General Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Goal**: Given some input $x_i$ and some trained model $\\hat{y}$, output some prediction denotated $\\hat{y}(x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input:** $$x_i \\overset{\\Delta}{=} [x_{i1}, x_{i2}, ..., x_{iF}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\overset{\\Delta}{=}$: the symbol for \"definition\". Read as, x \"is defined as\" y\n",
    "- $x_i$: This here represents a single feature vector. There could be many others in the input. Note that each element of $x_i$ has to be numeric\n",
    "- $F$: Indicates that the feature vector $x_i$ has F elements\n",
    "- **Aliases**: features, covariates, predictors, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:** $$\\hat{y}(x_i) \\in \\mathbb{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\hat{}$: This indicates that something is a predictor. In this case, we show that the model $\\hat{y}$ predicts a response\n",
    "- $x_i$: The use of subscript $i$ means each feature vector warrants an individual response\n",
    "- $\\mathbb{R}$: This indicates that the return value for the predictor is a real number, and is also a scalar value\n",
    "- **Aliases**: Responses, labels "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# x_NF is a matrix of N feature vectors, with each feature vector being of length F\n",
    "# For every feature vector of x_NF, the model predicts one scalar value. All the scalar values\n",
    "# are returned in a N x 1 size vector\n",
    "\n",
    "yhat_N1 = model.predict(x_NF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - General Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Given some number $N$ of feature vectors, and their cooresponding correct values, output a trained model $\\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input:** $$\\{x_n, y_n\\}^N_{n=1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x_n$: This denotes an entire feature vector. Thus, $x$ represents the array of queries, each of which can be an $m^{th}$ dimensional feature vector\n",
    "- $y_n$: This is a cooresponding scalar. $y$ is an array of these scalars, such that for some index $i$, $\\{x_i, y_i\\} \\forall i < N$ will form a valid labeled input pair\n",
    "- $N$: This means that there are $N$ number of feature vectors and $N$ cooresponding scalar values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:** $$\\hat{y}(\\cdot) : \\mathbb{R}^F \\rightarrow \\mathbb{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\hat{y}$: Name/denotation of the function\n",
    "- $\\cdot$: This means that $\\hat{y}$ takes some input. In this case, it takes a vector. Note that $\\cdot$ is just shorthand for a  variable when we don't want to add another English or Greek symbol\n",
    "- $\\mathbb{R}^F \\rightarrow \\mathbb{R}$: This specifies that $\\hat{y}$ is a function which takes a $F$ dimensional vector and returns a real number $\\mathbb{R}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# x_NF is a matrix of N feature vectors, wwith each feature vector being of length F\n",
    "# y_N1 is a matrix of N single element arrays, each of which contains a scalar cooresponding to its index at x_NF\n",
    "\n",
    "model.fit(x_NF, y_N1) # This trains the model and updates its internal state. Nothing is returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating - General Concept "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Given a vector of values predicted using the inputs of the training set $x$, and another vector of values which coorespond to the actual outputs of $x$, output a scalar measure of either the error or quality of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input:** $$\\{\\hat{y}(x_n), y_n\\}^N_{n = 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\hat{y}(x_n)$: Predicted value each feature vector $x_n$ such that $x_n$ has a real cooresponding value in the training dataset. This is required as the input values $x_n$ need to have an \"actual value\" counterpart in order for us to calculate error\n",
    "- $y_n$: The real cooresponding values of $x_n$ in the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:** $$scalar$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any input $x_n$, the individual error between these values $y_n$ and $\\hat{y}(x_n)$ is equal to their distance. The scalar output is the average of all these distances after they have been turned positive. The method of turning these distance values positive is done either through (1) squaring or (2) taking their absoloute value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mean Squared Error:* $$\\frac{1}{N} \\sum^N_{n=1} (y_n - \\hat{y}_n)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Squared Error method takes two vectors of size $N$, subtracts each value of the vector from each other, squares each value, and then takes the average of the resulting vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mean Absolute Error:* $$\\frac{1}{N} \\sum^N_{n=1} |y_n - \\hat{y}_n|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Absoloute Error method takes two vectors of size $N$, subtracts each value of the vector from the other, takes the absoloute value of each value, and then takes the average of the resuling vector. Template implementation is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_actual, y_hat):\n",
    "    N = y_actual.shape[0]\n",
    "    top = np.square(y_actual - y_hat) #change square to abs depending on implementation\n",
    "    return (np.sum(top))/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model:**\n",
    "Linear regression is basically $y=mx+b$ on $F$ dimensions, such that linear regression on $F$ features it generates a $F-1$ dimensional line/plane\n",
    "- $w = [w_1, w_2, ..., w_F]$: The weight vector is the same length (same shape?) as the feature vector it trained on. \n",
    "- $b$: This is the bias that has to be applied to each feature of the input feature vector during prediction time. Think about this as the intercept in $y=mx+b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execution:** $$\\hat{y}(x_i) \\overset{\\Delta}{=} \\sum^F_{f=1} (w_f x_{if}+b)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This is for some trained model $\\hat{y}$. How the model is trained comes later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x_i$: An entire feature vector, and $x_{if}$ is an element of the feature vector\n",
    "- $w$: The weight vector, and $w_f$ is an element of the weight vector\n",
    "- The shape of $x_{if}$ and $w_i$ need to be the same [[__???__]]\n",
    "- $F$: The length of a feature vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
